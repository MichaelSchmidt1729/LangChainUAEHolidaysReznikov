{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichaelSchmidt1729/LangChainUAEHolidaysReznikov/blob/main/LangChain_UAE_Holidays_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install all proper packages\n",
        "!pip install chromadb==0.3.25 pydantic==1.10.9 openai==0.27.8 bs4 tiktoken==0.4.0 langchain==0.0.235 huggingface_hub==0.16.4 sentence_transformers==2.2.2 pandas> /dev/null"
      ],
      "metadata": {
        "id": "KCTmQXihq9Jk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Download\n",
        "Firstly, we will fetch the data from a website containing information about the official public holidays in the UAE for this year. To work with our own data, we will save the table as a CSV file and later load it using the `CSVLoader`. Theoretically, one can use `WebCrawler` instead of a custom function or include our function in a tool."
      ],
      "metadata": {
        "id": "0R1h4Ivn8ETR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import bs4\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gXypMluAjBME"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make HTTP GET request\n",
        "def get_request(url, cookies={}, headers={}):\n",
        "    return requests.get(url, cookies=cookies, headers=headers)\n",
        "\n",
        "# Function to collect data from a URL and extract the table\n",
        "def collect_data(url):\n",
        "    response = get_request(url)\n",
        "    soup = bs4.BeautifulSoup(response.text, features=\"lxml\")\n",
        "    table = soup.find(\"table\", class_=\"publicholidays\")\n",
        "    return table\n",
        "\n",
        "# Function to convert HTML table to pandas DataFrame\n",
        "def convert_html_table_to_df(html_text):\n",
        "    return pd.read_html(str(html_text))[0]"
      ],
      "metadata": {
        "id": "pe3kftmBioJw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install BeautifulSoup\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "###\n",
        "# Root URL for the website containing holiday data\n",
        "ROOT_URL = \"https://publicholidays.ae/2023-dates/\"\n",
        "\n",
        "# HTML mit BeautifulSoup parsen\n",
        "soup = BeautifulSoup(html_text, 'html.parser')\n",
        "\n",
        "# Daten extrahieren\n",
        "data = []\n",
        "for row in soup.find_all(\"p\", class_=\"row\"):\n",
        "    # Annahme: Die Daten sind durch Kommas getrennt und jedes Stück hat den Format 'Schlüssel: Wert'\n",
        "    row_data = row.get_text().split(', ')\n",
        "    row_dict = {item.split(': ')[0]: item.split(': ')[1] for item in row_data}\n",
        "    data.append(row_dict)\n",
        "\n",
        "# Daten in DataFrame konvertieren\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Collect the data and convert it to a DataFrame\n",
        "html_text = collect_data(url=ROOT_URL)\n",
        "df = convert_html_table_to_df(html_text=html_text)\n",
        "###"
      ],
      "metadata": {
        "id": "VorPAnLqmNEQ",
        "outputId": "34c1f498-d2b2-4d5b-ef0f-39b9b5050419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No tables found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b361d475070f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Collect the data and convert it to a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhtml_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mROOT_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_html_table_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhtml_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-54e3665463e6>\u001b[0m in \u001b[0;36mconvert_html_table_to_df\u001b[0;34m(html_text)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Function to convert HTML table to pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_html_table_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m     return _parse(\n\u001b[0m\u001b[1;32m   1206\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0mio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mretained\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mretained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;31m# if `io` is an io-like object, check if it's seekable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mparse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \"\"\"\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_thead_tbody_tfoot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse_tables\u001b[0;34m(self, doc, match, attrs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No tables found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No tables found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "X4p0goVfioMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "df.iloc[:-1, :].to_csv(\"uae_holidays.csv\")"
      ],
      "metadata": {
        "id": "bvfDNzHgsxoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain\n",
        "Now, we will import several LangChain methods that we will be utilizing. For the purposes of this demo, we will begin with a straightforward approach using the `ChatOpenAI` model. To achieve this, we will load the previously saved file and create a vector index from its contents. Additionally, we will create a simple prompt and set up a memory to store the conversation history. Finally, we will configure a `RetrievalQA` chain to bring all these components together."
      ],
      "metadata": {
        "id": "HVua_HRq8r5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "erN0kcg3ioPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load language model, embeddings, and index for conversational AI\n",
        "from langchain.chat_models import ChatOpenAI                #model\n",
        "from langchain.indexes import VectorstoreIndexCreator       #index\n",
        "from langchain.document_loaders.csv_loader import CSVLoader #tool\n",
        "from langchain.prompts import PromptTemplate                #prompt\n",
        "from langchain.memory import ConversationBufferMemory       #memory\n",
        "from langchain.chains import RetrievalQA                    #chain\n",
        "\n",
        "#import langchain\n",
        "#langchain.verbose = True"
      ],
      "metadata": {
        "id": "aiDRzpEQDMR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_llm():\n",
        "    llm = ChatOpenAI(temperature=0,model_name=\"gpt-3.5-turbo\")\n",
        "    return llm\n",
        "\n",
        "def load_index():\n",
        "    # if you want to avoid the step of saving/loading a file, you can use the `from_documents()` method of the VectorstoreIndexCreator()\n",
        "    loader = CSVLoader(file_path='uae_holidays.csv')\n",
        "    index = VectorstoreIndexCreator().from_loaders([loader])\n",
        "    return index"
      ],
      "metadata": {
        "id": "jyqM7hbGsUMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "You are a assistant to help answer when are the official UAE holidays, based only on the data provided.\n",
        "Context: {context}\n",
        "-----------------------\n",
        "History: {chat_history}\n",
        "=======================\n",
        "Human: {question}\n",
        "Chatbot:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Create a prompt using the template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"context\", \"question\"],\n",
        "    template=template\n",
        ")"
      ],
      "metadata": {
        "id": "YhpmgQJL9mra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up conversation memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, input_key=\"question\")"
      ],
      "metadata": {
        "id": "sVgjt827-m2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the retrieval-based conversational AI\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=load_llm(),\n",
        "    chain_type='stuff',\n",
        "    retriever=load_index().vectorstore.as_retriever(),\n",
        "    verbose=True,\n",
        "    chain_type_kwargs={\n",
        "        \"prompt\": prompt,\n",
        "        \"memory\": memory,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "NwcoF-2u4lkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q&A\n",
        "Let's now ask some questions regarding the holidays in UAE:"
      ],
      "metadata": {
        "id": "Vw6gWqOZ_adn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print the response for a given query\n",
        "def print_response_for_query(query):\n",
        "    return print(qa.run({\"query\": query}))"
      ],
      "metadata": {
        "id": "8IFJ1-2twoNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Holidays in March/December"
      ],
      "metadata": {
        "id": "Bhoa6gEhyIdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Are there any holidays in March?\"\n",
        "print_response_for_query(query)"
      ],
      "metadata": {
        "id": "7iBQrEavx2B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correct response. What about December?"
      ],
      "metadata": {
        "id": "PgnCfZoMyEf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Sorry, I meant December\"\n",
        "print_response_for_query(query)"
      ],
      "metadata": {
        "id": "FOYD4BnRYuPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did you notice, how we used the **memory** here? If it wasn't for it, the response would've sounded as:\n",
        "> Sorry, I can't understand you. What exactly are you looking for in December?\n",
        "\n",
        "It is worth noticing, that despite having an error in counting <font color='red'>two</font> the response contains all <font color='green'>three</font> holiday. Prompt upgrade may probably solve the issue."
      ],
      "metadata": {
        "id": "7DrUjBA7yDmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multichain Ramadan example"
      ],
      "metadata": {
        "id": "4RXVGMmpzRJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"When does this year's holiday marking the end of Ramadan start?\"\n",
        "print_response_for_query(query)"
      ],
      "metadata": {
        "id": "v6uyhVH1o7rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now this is quite interesting. The chain correctly identified Eid al-Fitr as the holiday that marks the end of Ramadan. But there is a reason, why I'm starting with scraping, instead of clean csv file. As you may notice, from the table, there is only one holiday called \"Eid al-Fitr\":\n",
        "\n",
        "| Date | Day | Holiday |\n",
        "| --- | --- | --- |\n",
        "| 20 Apr | Thu | Eid al-Fitr Holiday |\n",
        "| 21 Apr | Fri | Eid al-Fitr |\n",
        "| 22 Apr | Sat | Eid al-Fitr Holiday |\n",
        "| 23 Apr | Sun | Eid al-Fitr Holiday |\n",
        "\n",
        "The problem here is that the data is dirty and the model can't identify, that it's actually a 4-day holiday. Of course the easy solution here would be to either clean the data, possibly through tools or modify prompt."
      ],
      "metadata": {
        "id": "3nSoM_UhzaJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How many days is it celebrated for this year?\"\n",
        "print_response_for_query(query)"
      ],
      "metadata": {
        "id": "RRCDJUG5xY4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is the next holiday?"
      ],
      "metadata": {
        "id": "12Go2I0Q1Dd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Today is July 16. When is the nearest holiday?\"\n",
        "print_response_for_query(query)"
      ],
      "metadata": {
        "id": "i8jntw9JzOmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As one can see the nearest holiday is detected correctly. A math tool looks for the closest date from the data provided"
      ],
      "metadata": {
        "id": "Oj7oj_Vl1JkF"
      }
    }
  ]
}